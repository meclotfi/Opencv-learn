{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Image manipulation\n",
    "1. transfoemations,affine and non affine\n",
    "\n",
    "2. translations\n",
    "\n",
    "3. Rotations\n",
    "\n",
    "4. Scaling,re-sizing and interpolations\n",
    "\n",
    "5. Image pyramids\n",
    "\n",
    "6. Cropping\n",
    "\n",
    "7. Arithmetic operations\n",
    "\n",
    "8. Bitwise operations\n",
    "\n",
    "9. Convulotions and Blurring\n",
    "\n",
    "10. sharpening\n",
    "\n",
    "11. thresholding and Binarization\n",
    "\n",
    "12. Dilation,erosion,oppening and closing\n",
    "\n",
    "13. Edge detection\n",
    "\n",
    "14. Perspective and Affine transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. translation\n",
    "is an affine transformation that shift image in a given direction ubtained by multiplying\n",
    "the matrix image with T=[[1,0,Tx],[0,1,Ty]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img=cv.imread(\"./images/input.jpg\")\n",
    "h,w=img.shape[:2]\n",
    "#\n",
    "T=np.array([[1,0,h/8],[0,1,w/8]])\n",
    "trans_img=cv.warpAffine(img,T,(h,w))\n",
    "cv.imshow(\"translation\",trans_img)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Rotations\n",
    "multiply by M=[[cos&,-sin&],[sin&,cos&]] while & is the angle of rotation\n",
    "cv2.getRotationMatrix2D(rotation_center_x, rotation_center_y, angle of rotation, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "R=cv.getRotationMatrix2D((h/2,w/2),90,1)\n",
    "Rotated_img=cv.warpAffine(img,R,(h,w))\n",
    "cv.imshow(\"Rotation\",Rotated_img)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " #Let's now to a horizontal flip.\n",
    "flipped = cv.flip(img, -1)\n",
    "cv.imshow('Horizontal Flip', flipped)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4. Scaling, re-sizing and interpolations\n",
    "interpolation is a method used to construct new data points within range of a discrete set of known data points\n",
    "it is very important when resizing an image to fill the gaps between pixels\n",
    "there a lot of interpolation techniques implemented by Opencv (see doc)\n",
    "\n",
    "Resizing is very easy in opencvusing the method\n",
    "cv2.resize(image, dsize(output image size), x scale, y scale, interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "linInter=cv.resize(img,None,fx=0.75,fy=0.75)\n",
    "cv.imshow(\"\",linInter)\n",
    "cv.waitKey()\n",
    "# Cubic Interpolation\n",
    "linInter=cv.resize(img,None,fx=2,fy=2,interpolation = cv.INTER_CUBIC)\n",
    "cv.imshow(\"\",linInter)\n",
    "cv.waitKey()\n",
    "# Area Interp√¥lation(best for down sampling)\n",
    "linInter=cv.resize(img,(900,600),interpolation = cv.INTER_AREA)\n",
    "cv.imshow(\"\",linInter)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Image pyramids \n",
    "technique used in resizing that help us get multiple downsizing copies of the same image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "copies=4\n",
    "pyramid=img\n",
    "for i in range(0,copies):\n",
    "    pyramid=cv.pyrDown(pyramid)\n",
    "    cv.imshow(\"\",pyramid)\n",
    "    cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: be careful with resizing because once you downsize your image you can not upsize it with the same quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "small=cv.pyrDown(img)\n",
    "cv.imshow(\"\",img)\n",
    "cv.waitKey()\n",
    "large=cv.pyrUp(small)\n",
    "large=cv.imshow(\"image after downsizing and upsizing\",large)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Cropping:\n",
    "extract a part of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the starting pixel coordiantes (top  left of cropping rectangle)\n",
    "start_row, start_col = int(h * .25), int(w * .25)\n",
    "\n",
    "# Let's get the ending pixel coordinates (bottom right)\n",
    "end_row, end_col = int(h * .75), int(w * .75)\n",
    "\n",
    "# Simply use indexing to crop out the rectangle we desire\n",
    "cropped = img[start_row:end_row , start_col:end_col]\n",
    "\n",
    "cv.imshow(\"Original Image\", img)\n",
    "cv.waitKey(0) \n",
    "cv.imshow(\"Cropped Image\", cropped) \n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 7. Arithmetic Operations:\n",
    "are basically adding or substracting matrices to the image which has the effect of increasing or deacring brightness or intensity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "M=np.ones(img.shape,dtype=\"uint8\")*100\n",
    "added=img+M\n",
    "cv.imshow(\"adding M\",added)\n",
    "subbe=img-M\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.imshow(\"sub M\",subbe)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 8.Bitwise opeartions:\n",
    "Operations like And,Or,Xor,Not are useful in masking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# If you're wondering why only two dimensions, well this is a grayscale image,\n",
    "# if we doing a colored image, we'd use\n",
    "# rectangle = np.zeros((300, 300, 3),np.uint8)\n",
    "\n",
    "# Making a sqare\n",
    "square = np.zeros((300, 300), np.uint8)\n",
    "cv.rectangle(square, (50, 50), (250, 250), 255, -2)\n",
    "cv.imshow(\"Square\", square)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Making a ellipse\n",
    "ellipse = np.zeros((300, 300), np.uint8)\n",
    "cv.ellipse(ellipse, (150, 150), (150, 150), 30, 0, 180, 255, -1)\n",
    "cv.imshow(\"Ellipse\", ellipse)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# Shows only where they intersect\n",
    "And = cv.bitwise_and(square, ellipse)\n",
    "cv.imshow(\"AND\", And)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Shows where either square or ellipse is\n",
    "bitwiseOr = cv.bitwise_or(square, ellipse)\n",
    "cv.imshow(\"OR\", bitwiseOr)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Shows where either exist by itself\n",
    "bitwiseXor = cv.bitwise_xor(square, ellipse)\n",
    "cv.imshow(\"XOR\", bitwiseXor)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Shows everything that isn't part of the square\n",
    "bitwiseNot_sq = cv.bitwise_not(square)\n",
    "cv.imshow(\"NOT - square\", bitwiseNot_sq)\n",
    "cv.waitKey(0)\n",
    "\n",
    "### Notice the last operation inverts the image totally\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 9. Convolution and Blurring\n",
    "convolution is a mathematical operation performed on two functions producing a third one which is typically a modified version of the one of the original one's"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "### bluring using a 3,3 matrice\n",
    "kernel=np.ones((3,3),dtype=\"uint8\")/9\n",
    "blu3_img=cv.filter2D(img,-1,kernel)\n",
    "cv.imshow(\"blu3\",blu3_img)\n",
    "cv.waitKey(0)\n",
    "\n",
    "### bluring using a 9,9 matrice\n",
    "kernel=np.ones((9,9),dtype=\"uint8\")/81\n",
    "blu9_img=cv.filter2D(img,-1,kernel)\n",
    "cv.imshow(\"blu9_img\",blu9_img)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "########other commmonly used blurring methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Averaging done by convolving the image with a normalized box filter.\n",
    "# This takes the pixels under the box and replaces the central element\n",
    "# Box size needs to odd and positive\n",
    "blur = cv.blur(img, (3,3))\n",
    "cv.imshow('Averaging', blur)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Instead of box filter, gaussian kernel\n",
    "Gaussian = cv.GaussianBlur(img, (7,7), 0)\n",
    "cv.imshow('Gaussian Blurring', Gaussian)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Takes median of all the pixels under kernel area and central\n",
    "# element is replaced with this median value\n",
    "median = cv.medianBlur(img, 5)\n",
    "cv.imshow('Median Blurring', median)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Bilateral is very effective in noise removal while keeping edges sharp\n",
    "bilateral = cv.bilateralFilter(img, 9, 75, 75)\n",
    "cv.imshow('Bilateral Blurring', bilateral)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "########## Image De-noising - Non-Local Means Denoising\n",
    "There are 4 variations of Non-Local Means Denoising:\n",
    "\n",
    "cv2.fastNlMeansDenoising() - works with a single grayscale images\n",
    "cv2.fastNlMeansDenoisingColored() - works with a color image.\n",
    "cv2.fastNlMeansDenoisingMulti() - works with image sequence captured in short period of time (grayscale images)\n",
    "cv2.fastNlMeansDenoisingColoredMulti() - same as above, but for color images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\n",
    "# Parameters, after None are - the filter strength 'h' (5-10 is a good range)\n",
    "# Next is hForColorComponents, set as same value as h again\n",
    "#\n",
    "dst = cv.fastNlMeansDenoisingColored(img, None, 6, 6, 7, 21)\n",
    "\n",
    "cv.imshow('Fast Means Denoising', dst)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "####### 10.Sharpening\n",
    "the opposite of blurring ,it strenghthen and emphasize edges in an image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "kernel=np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "sharp_age=cv.filter2D(img,-1,kernel)\n",
    "\n",
    "cv.imshow('Sharped Image', sharp_age)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 11.Thresholding, Binarization & Adaptive Thresholding\n",
    "In thresholding, we convert a grey scale image to it's binary form"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "# Values below 127 goes to 0 (black, everything above goes to 255 (white)\n",
    "ret,thresh1 = cv.threshold(img, 127, 255, cv.THRESH_BINARY)\n",
    "cv.imshow('1 Threshold Binary', thresh1)\n",
    "cv.waitKey(0)\n",
    "# Values below 127 go to 255 and values above 127 go to 0 (reverse of above)\n",
    "ret,thresh2 = cv.threshold(img, 127, 255, cv.THRESH_BINARY_INV)\n",
    "cv.imshow('2 Threshold Binary Inverse', thresh2)\n",
    "cv.waitKey(0)\n",
    "# Values above 127 are truncated (held) at 127 (the 255 argument is unused)\n",
    "ret,thresh3 = cv.threshold(img, 127, 255, cv.THRESH_TRUNC)\n",
    "cv.imshow('3 THRESH TRUNC', thresh3)\n",
    "cv.waitKey(0)\n",
    "# Values below 127 go to 0, above 127 are unchanged\n",
    "ret,thresh4 = cv.threshold(img, 127, 255, cv.THRESH_TOZERO)\n",
    "cv.imshow('4 THRESH TOZERO', thresh4)\n",
    "cv.waitKey(0)\n",
    "# Resever of above, below 127 is unchanged, above 127 goes to 0\n",
    "ret,thresh5 = cv.threshold(img, 127, 255, cv.THRESH_TOZERO_INV)\n",
    "cv.imshow('5 THRESH TOZERO INV', thresh5)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Is there a better way off thresholding?\n",
    "\n",
    "The biggest downfall of those simple threshold methods is that we need to provide the threshold value (i.e. the 127 value we used previously).\n",
    "What if there was a smarter way of doing this?\n",
    "There is with, Adaptive thresholding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-2b5g8ysb\\opencv\\modules\\imgproc\\src\\thresh.cpp:1676: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'cv::adaptiveThreshold'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-22-65e89e510ee2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Using adaptiveThreshold\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mthresh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madaptiveThreshold\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m255\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mADAPTIVE_THRESH_MEAN_C\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTHRESH_BINARY\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Adaptive Mean Thresholding\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthresh\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwaitKey\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-2b5g8ysb\\opencv\\modules\\imgproc\\src\\thresh.cpp:1676: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'cv::adaptiveThreshold'\n"
     ]
    }
   ],
   "source": [
    "# It's good practice to blur images as it removes noise\n",
    "image = cv.GaussianBlur(img, (3, 3), 0)\n",
    "\n",
    "# Using adaptiveThreshold\n",
    "thresh = cv.adaptiveThreshold(image, 255, cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY, 3, 5)\n",
    "cv.imshow(\"Adaptive Mean Thresholding\", thresh)\n",
    "cv.waitKey(0)\n",
    "\n",
    "_, th2 = cv.threshold(image, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "cv.imshow(\"Otsu's Thresholding\", th2)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv.GaussianBlur(img, (5,5), 0)\n",
    "_, th3 = cv.threshold(blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "cv.imshow(\"Guassian Otsu's Thresholding\", th3)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 12. Dilation,Erosion ,Opening, Closing\n",
    "Dilation: add pixels to the boundaries of objects in images)\n",
    "Erosion : remove pixels of the boundaries of objects in an Image\n",
    "Opening: E->D\n",
    "Closing: D->E\n",
    "\n",
    "O and C are great tools for noise removing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "# Now we erode\n",
    "erosion = cv.erode(image, kernel, iterations = 1)\n",
    "cv.imshow('Erosion', erosion)\n",
    "cv.waitKey(0)\n",
    "\n",
    "#\n",
    "dilation = cv.dilate(image, kernel, iterations = 1)\n",
    "cv.imshow('Dilation', dilation)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Opening - Good for removing noise\n",
    "opening = cv.morphologyEx(image, cv.MORPH_OPEN, kernel)\n",
    "cv.imshow('Opening', opening)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Closing - Good for removing noise\n",
    "closing = cv.morphologyEx(image, cv.MORPH_CLOSE, kernel)\n",
    "cv.imshow('Closing', closing)\n",
    "cv.waitKey(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are some other less popular morphology operations, see the official OpenCV site:\n",
    "http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 13. Edge detection and image gradient\n",
    "Edges can be defined as sudden changes in image\n",
    "edge detection is a very importatnt area in computer vision specially when dealing with countours\n",
    "OpenCv many types of edge detection algo such as:\n",
    "* Sobel: to emphasize vertical and horizontal edges\n",
    "* Lapalacian: Gets all orientations\n",
    "* Canny : Optimal due to its low error rate (see more abut Canny)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "image=img\n",
    "# Extract Sobel Edges\n",
    "sobel_x = cv.Sobel(image, cv.CV_64F, 0, 1, ksize=5)\n",
    "sobel_y = cv.Sobel(image, cv.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "cv.imshow('Original', image)\n",
    "cv.waitKey(0)\n",
    "cv.imshow('Sobel X', sobel_x)\n",
    "cv.waitKey(0)\n",
    "cv.imshow('Sobel Y', sobel_y)\n",
    "cv.waitKey(0)\n",
    "\n",
    "sobel_OR = cv.bitwise_or(sobel_x, sobel_y)\n",
    "cv.imshow('sobel_OR', sobel_OR)\n",
    "cv.waitKey(0)\n",
    "\n",
    "laplacian = cv.Laplacian(image, cv.CV_64F)\n",
    "cv.imshow('Laplacian', laplacian)\n",
    "cv.waitKey(0)\n",
    "\n",
    "\n",
    "##  Then, we need to provide two values: threshold1 and threshold2. Any gradient value larger than threshold2\n",
    "# is considered to be an edge. Any value below threshold1 is considered not to be an edge.\n",
    "#Values in between threshold1 and threshold2 are either classiÔ¨Åed as edges or non-edges based on how their\n",
    "#intensities are ‚Äúconnected‚Äù. In this case, any gradient values below 60 are considered non-edges\n",
    "#whereas any values above 120 are considered edges.\n",
    "\n",
    "\n",
    "# Canny Edge Detection uses gradient values as thresholds\n",
    "# The first threshold gradient\n",
    "canny = cv.Canny(image, 50, 120)\n",
    "cv.imshow('Canny', canny)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Perspective and Affine transforms\n",
    "In affine transforms you only need 3 coordiantes to obtain the correct transform"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = cv.imread('images/scan.jpg')\n",
    "\n",
    "cv.imshow('Original', image)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Cordinates of the 4 corners of the original image\n",
    "points_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n",
    "\n",
    "# Cordinates of the 4 corners of the desired output\n",
    "# We use a ratio of an A4 Paper 1 : 1.41\n",
    "points_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n",
    "\n",
    "# Use the two sets of four points to compute\n",
    "# the Perspective Transformation matrix, M\n",
    "M = cv.getPerspectiveTransform(points_A, points_B)\n",
    "\n",
    "warped = cv.warpPerspective(image, M, (420,594))\n",
    "\n",
    "cv.imshow('warpPerspective', warped)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}